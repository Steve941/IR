---
title: "R-Code Visualizing of IR"
author: "Stefan Glogger"
date: "2 August 2017"
output: pdf_document
---


\newpage


# Data Visualization

overall to use

Lines with data
```{r}
geomLineDataDAX <- function(x){
    parse(text = paste0("geom_line(data = ", x, ", aes(x = dates, y = DAX, colour = \"DAX\"))")) 
}
geomLineDataTEC <- function(x){
    parse(text = paste0("geom_line(data = ", x, ", aes(x = dates, y = TEC, colour = \"TEC\"))"))
}
geomLineDataESX50 <- function(x){
    parse(text = paste0("geom_line(data = ", x, ", aes(x = dates, y = ESX50, colour = \"ESX50\"))")) 
}
geomLineDataSP5 <- function(x){
    parse(text = paste0("geom_line(data = ", x, ", aes(x = dates, y = SP5, colour = \"SP5\"))")) 
}
geomLineDataNASDAQ <- function(x){
    parse(text = paste0("geom_line(data = ", x, ", aes(x = dates, y = NASDAQ, colour = \"NASDAQ\"))"))
}
geomLineDataNIKKEI <- function(x){
    parse(text = paste0("geom_line(data = ", x, ", aes(x = dates, y = NIKKEI, colour = \"NIKKEI\"))"))
}
geomLineDataBUND <- function(x){
    parse(text = paste0("geom_line(data = ", x, ", aes(x = dates, y = BUND, colour = \"BUND\"))")) 
}
```


probierer, funktioniert nicht (wollte alle linien auf einmal plotten)
```{r, run = FALSE}
# geomLineData <- function(x){
#     parse(text = paste0("eval(geomLineDataDAX(\"", x , "\")) + eval(geomLineDataTEC(\"", x , "\"))"))
# }
# 
# ggplot() +
#     eval(geomLineData("retPlot")) +
#     eval(geomRectDateLast) +
#     labs(x = "Time", y = "Value")
```






Rectangle for Date periods

```{r}
geomRectDateLast <- parse(text = "geom_rect(aes(xmin = dateMinEvalLast, xmax = dateMaxEvalLast, ymin = -Inf, ymax = Inf), alpha = 0.2 , fill = \"orange\")")

geomRectDateBear <- parse(text = "geom_rect(aes(xmin = min(datesEvalBear), xmax = max(datesEvalBear), ymin = -Inf, ymax = Inf), alpha = 0.2 , fill = \"red\")")

geomRectDateBull <- parse(text = "geom_rect(aes(xmin = min(datesEvalBull), xmax = max(datesEvalBull), ymin = -Inf, ymax = Inf), alpha = 0.2 , fill = \"green\")")
```


```{r}
plotData <- function(x){
    ggplot() +
        eval(geomLineDataDAX(x)) +
        eval(geomLineDataTEC(x)) +
        eval(geomLineDataESX50(x)) +
        eval(geomLineDataNASDAQ(x)) +
        eval(geomLineDataNIKKEI(x)) +
        eval(geomLineDataBUND(x)) +
        eval(geomRectDateLast) +
        eval(geomRectDateBear) +
        eval(geomRectDateBull) +
        labs(x = "Time", y = "Value")
}

## if a special name is given, take it, otherwise take x (plot sentix by using same dataframe (adopted))
plotDataPDF <- function(x, xName = x){
    pdf(file.path(getwd(), "Plot Data", paste0(xName, ".pdf")), width = 10, height = 4)
    plot(plotData(x))
    dev.off()
}
```


## Stocks

Start of with 100 for each stock and then plot the returns.

```{r}
retPlot <- matrix(100, nrow = nrow(stocks), ncol = ncol(stocks)-1)
retPlot[2:nrow(stocks), ] <- 1+ret # to multiply lateron, we have to add 1
retPlot <- apply(retPlot, 2, cumprod)
rownames(retPlot) <- stocks[,1]

x <- rownames(retPlot)
xNames <- x
class(xNames) <- "Date"   # convert to date

cols <- rainbow(ncol(retPlot))
ylim <- c(min(retPlot), max(retPlot))
plot(xNames, retPlot[,1], type = "l", xlab = "Date", ylab = "Value", col = cols[1],
     ylim = ylim)
for(i in 2:ncol(retPlot)){
    par(new=T)
    plot(xNames, retPlot[,i], type = "l", col = cols[i], axes = F, xlab="", ylab="", ylim = ylim)
}
legend("topleft", legend = colnames(stocks)[2:ncol(stocks)], col = cols, lty = 1)
```

```{r}
# library(ggplot2)
```

need data frame as input for ggplot

```{r}
retPlot <- matrix(100, nrow = nrow(stocks), ncol = ncol(stocks)-1)
retPlot[2:nrow(stocks), ] <- 1+ret # to multiply lateron, we have to add 1
retPlot <- apply(retPlot, 2, cumprod)

retPlot <- as.data.frame(retPlot)
colnames(retPlot) <- colnames(stocks)[2:ncol(stocks)]
retPlot$dates <- stocks[,1]
class(retPlot$dates) <- "Date"   # convert to date

cols <- rainbow(ncol(retPlot))
ylim <- c(min(retPlot[,1:(ncol(retPlot)-1)]), max(retPlot[,1:(ncol(retPlot)-1)]))


plotData("retPlot")
plotDataPDF("retPlot")
```



```{r}
ggplot() +
    geom_line(data = retPlot, aes(x = dates, y = DAX, colour = "DAX")) +
    geom_line(data = retPlot, aes(x = dates, y = TEC, colour = "TEC")) +
    geom_line(data = retPlot, aes(x = dates, y = ESX50, colour = "ESX50")) +
    geom_line(data = retPlot, aes(x = dates, y = NASDAQ, colour = "NASDAQ")) +
    geom_line(data = retPlot, aes(x = dates, y = NIKKEI, colour = "NIKKEI")) +
    geom_line(data = retPlot, aes(x = dates, y = BUND, colour = "BUND")) +
    geom_rect(aes(xmin = dateMinEvalLast, xmax = dateMaxEvalLast, ymin = -Inf, ymax = Inf), alpha = 0.2 , fill = "orange") +
        labs(x = "Time", y = "Value")
```


## Dispersion

As we need additionally the columen 'dates' in the dataframe to plot it conveniently.

```{r}
sentDataPlot <- function(x){
    t <- x
    t$dates <- as.Date(rownames(x))
    return(t)
}
```


```{r}
for(i in sentixDataNames){
    sPlot <- sentDataPlot(get(i))
    plotDataPDF("sPlot", i)
}
```


\newpage
# Optimization of Portfolios

We evaluate an optimal portfolio at each date within our test season and assume that we can redistribute our wealth at no cost.

```{r}
datesEvalLast <- dates[dates >= dateMinEvalLast & dates <= dateMaxEvalLast]
length(datesEvalLast)
```


## with sentiment (Grid Search)

### general setup

```{r}
# library(Rdonlp2) ## needed for donlp2NLP
# library(fPortfolio)
# library(FRAPO)
# library(mco) ## mrc
```

Setup Grid. Take care that weights sum up to 1.

```{r}
bySteps <- 0.05
wmin <- 0.05
wmax <- 0.95
grid <- expand.grid(w1 = seq(wmin, wmax, by = bySteps), w2 = seq(wmin, wmax, by = bySteps), w3 = seq(wmin, wmax, by = bySteps) )
grid <- grid[abs(rowSums(grid) - 1.0) < 0.0001,]
```

With this setup, we have `r nrow(grid)` combinations of weights.

variables for lookback
```{r}
sentLookback <- 20

# overview of what is used

head(ret) # returns

### no as if you want to reduce, reduce all data (also sentix data)
# # reduce for simplicity
# ret <- ret[rownames(ret) > "2014-01-01",]

targetRpm
targetVolpa

IneqA <- matrix(1, nrow = 1, ncol = numAsset)

# also typecast date to integer to speed up calculations
rownames(ret) <- as.integer(as.Date(rownames(ret)))
```



```{r}
ergSentixNames <- c()
i = 1
parse(text = paste0("ergSentixNames <- ", "c(ergSentixNames, \"erg", sentixDataNames[i], "\")"))
for(i in sentixDataNames){
    eval(parse(text = paste0("ergSentixNames <- ", "c(ergSentixNames, \"erg", i, "\")")))
}
```


### mrc


start optimization with equal weights and then start each iteration with result of previous iteration


roughly 30 seconds per strategy and weight (on laptop stefan)
```{r}
nrow(grid)*length(sentixDataNamesReg)*30 # Sekunden
nrow(grid)*length(sentixDataNamesReg)*30/60 # Minuten
nrow(grid)*length(sentixDataNamesReg)*30/60/60 # Stunden
```

roughly 14 seconds per strategy and weight (on laptop stefan)
```{r}
nrow(grid)*length(sentixDataNamesReg)*14 # Sekunden
nrow(grid)*length(sentixDataNamesReg)*14/60 # Minuten
nrow(grid)*length(sentixDataNamesReg)*14/60/60 # Stunden
```


Generate a list holding all data with structure (levels of list)
weights of goal function -> strategy -> dates -> weights of assets

```{r}
E <- list()
tt <- numeric(nrow(grid)*length(sentixDataNamesReg)) # track time to evaluate code

for(weightInd in 1:nrow(grid)){
    w <- as.numeric(grid[weightInd,])
    weightName <- paste(w, collapse = "-") # needed later to store result
    
    for(strategy in sentixDataNamesReg){
        SentData <- get(strategy)
        rownames(SentData) <- as.integer(as.Date(rownames(SentData))) # for faster comparison below -> cast date to integer
        erg <- matrix(NA, nrow = length(datesEvalLast)+1, ncol = numAsset) # +1 to lookup every weight
        rownames(erg) <- c("1000-01-01", paste(datesEvalLast))
        erg[1, ] <- rep(1/numAsset, numAsset)
        
        for(d in datesEvalLast){
            dInd <- which(datesEvalLast==d)
            
            SSent <- cov(SentData[(which(rownames(SentData) == d)-sentLookback):
                                      which(rownames(SentData) == d) - 1, ]) # -1 to just look in past
            rdat <- ret[unique(pmax(which(rownames(ret)<=d) - 1,1)),] # from beginning to one day in past
            muStock <- colMeans(rdat)
            SStock <- cov(rdat)
            
            erg[dInd+1,] <- donlp2NLP(start = erg[dInd,], obj = hWeighted, 
                         par.lower = rep(0, numAsset), ineqA = IneqA, 
                         ineqA.lower = 1.0, ineqA.upper = 1.0)$solution
        }
        
        E[[weightName]][[strategy]] <- erg
        tt[(weightInd-1)*nrow(grid) + which(sentixDataNamesReg == strategy)] <- proc.time()[3]
    }
}
save(E, file = file.path(folderData, "Optimization", paste0("Eserver_", format(Sys.time(), "%Y-%m-%d---%H-%M"))))
```

### dispersion direct min

do same calculations but plug in dispersion (sentiment) directly as third factor and want to minimize the dispersion

Generate a list holding all data with structure (levels of list)
weights of goal function -> dispersion (sentixDataNames) -> dates -> weights of assets

parallel programming with 

```{r}
# library(foreach)
# library(doParallel)
# library(doSNOW)
```


```{r}
cores <- detectCores()

if(Sys.getenv("USERNAME") == "Stefan"){
    cl <- makeCluster(cores - 1)
} else if(Sys.getenv("USERNAME") == "gloggest"){
    cl <- makeCluster(cores) # use server fully
} else
    stop("Who are you???")


E <- list()
tt <- numeric(nrow(grid)*length(sentixDataNamesReg)) # track time to evaluate code

# registerDoParallel(cl)
registerDoSNOW(cl)
E <- foreach(weightInd = 1:nrow(grid), .export = sentixDataNames, .packages = c("fPortfolio", "FRAPO")) %dopar% {
    w <- as.numeric(grid[weightInd,])
    weightName <- paste(w, collapse = "-") # needed later to store result
    
    for(strategy in sentixDataNames){
        SentData <- get(strategy)
        rownames(SentData) <- as.integer(as.Date(rownames(SentData))) # for faster comparison below -> cast date to integer
        erg <- matrix(NA, nrow = length(datesEvalLast)+1, ncol = numAsset) # +1 to lookup every weight
        rownames(erg) <- c("1000-01-01", paste(datesEvalLast))
        erg[1, ] <- rep(1/numAsset, numAsset)
        
        for(d in datesEvalLast){
            dInd <- which(datesEvalLast==d)
            
            
            dispersion <- SentData[which(rownames(SentData) == d)- 1, ] # -1 to just look at the sentiment in past
            rdat <- ret[unique(pmax(which(rownames(ret)<=d) - 1,1)),] # from beginning to one day in past
            muStock <- colMeans(rdat)
            SStock <- cov(rdat)
            
            erg[dInd+1,] <- donlp2NLP(start = erg[dInd,], obj = hWeighted, 
                         par.lower = rep(0, numAsset), ineqA = IneqA, 
                         ineqA.lower = 1.0, ineqA.upper = 1.0)$solution
        }
        
        E[[weightName]][[strategy]] <- erg
        tt[(weightInd-1)*nrow(grid) + which(sentixDataNamesReg == strategy)] <- proc.time()[3]
    }
}
stopCluster(cl)

save(E, file = file.path(folderData, "Optimization", paste0("EDispersionMin_", Sys.getenv("USERNAME"), format(Sys.time(), "%Y-%m-%d---%H-%M"))))
```



## without sentiment (classsic)

classical portfolio optimization

```{r, results='hide'}
t <- rownames(ret) # convert rownames back to date format (character!)
class(t) <- "Date"
rdatTimeSource <- timeSeries(ret, charvec = as.character(t))

ew <- rep(1/numAsset, numAsset)

Wmsr <- matrix(NA, nrow = length(datesEvalLast), ncol = numAsset)
Wmdp <- Wgmv <- Werc <- Wmsr

for(d in datesEvalLast){
    dInd <- which(datesEvalLast==d)
    class(d) <- "Date"
    rdatTime <- window(rdatTimeSource, start = start(rdatTimeSource), end = d-1) # just look at period before
    
    ans <- tangencyPortfolio(rdatTime)
    Wmsr[dInd, ] <- getWeights(ans)
    
    ### most diversified
    ans <- PMD(rdatTime)
    Wmdp[dInd, ] <- FRAPO::Weights(ans) / 100
    
    ### global minimum variance
    ans <- PGMV(rdatTime)
    Wgmv[dInd, ] <- FRAPO::Weights(ans) / 100
    
    ### risk parity optimization
    SStock <- cov(rdatTime)
    ans <- rp(ew, SStock, ew, optctrl = ctrl(trace = FALSE)) # maybe invisible() makes output silent
    Werc[dInd, ] <- c(getx(ans))
}

Eclassic <- list("MSR" = Wmsr, "MDP" = Wmdp, "GMV" = Wgmv, "ERC" = Werc)
```


# Portfolio Analysis

```{r}
# library(PerformanceAnalytics)
```


## with sentiment

```{r}
evolve
```

```{r}
Eevolving <- list()
for(weight in names(E)){
    Eevolving[[weight]] <- lapply(E[[weight]], evolve)
}
```

somehow an lapply doesn't work, so I implement everything again

```{r}
Eanalysis <- list()
for(weight in names(Eevolving)){
    # Eanalysis[[weight]] <- lapply(Eevolving[[weight]], analysePortfolio) # TODO somehow not working
    l <- Eevolving[[weight]]
    RsClassic <- matrix(unlist(lapply(l, Return.calculate)), ncol = length(l)) # return from time to time
    RsTSClassic <- na.omit(xts(RsClassic, order.by = as.Date(datesEvalLast)))
    bench <- xts(rep(0, nrow(RsTSClassic)), order.by = as.Date(datesEvalLast)[-1]) # benchmark 0 everytime
    
    S1 <- as.matrix(table.AnnualizedReturns(RsTSClassic, Rf = bench)) # scale is chosen automatically to 'weekly'
    S2 <- -1*VaR(RsTSClassic) # 95% as default (outputs small negative value)
    
    ans <- rbind(S1, S2)
    colnames(ans) <- names(l)
    rownames(ans) <- c("Return (p.a.)", "StdDev. Risk (p.a.)", "Sharpe Ratio", "VaR 95% (p.a.)")
    
    Eanalysis[[weight]] <- round(ans,3)
}
```

```{r}
names(Eanalysis)[20]
Eanalysis[[20]]

names(Eanalysis)[100]
Eanalysis[[100]]

names(Eanalysis)[150]
Eanalysis[[150]]
```

### find best portfolio

we have to apply our goaling function again to come up with best portfolios
TODO do this directly when determining the portfolios

for all weights: go through all dates, add corresponding objective value to objective value and divide at the very end through the number of dates -> average objective value per weight and strategy

```{r}
wNames <- character(nrow(grid))
for(k in 1:length(wNames)){
    wNames[k] <- paste0(grid[k,1], "-", grid[k,2], "-", grid[k,3])
}

i <- sentixDataNames[1]
parse(text = paste0(i, "ObjValue <- data.frame(\"w1\" = grid[,1], \"w2\" = grid[,2], \"w3\" = grid[,3], \"h\" = 0)"))
for(i in sentixDataNamesReg){
    eval(parse(text = paste0(i, "ObjValue <- data.frame(\"w1\" = grid[,1], \"w2\" = grid[,2], \"w3\" = grid[,3], \"h\" = 0)")))
    eval(parse(text = paste0("rownames(", i, "ObjValue) <- wNames")))
}

for(d in datesEvalLast){
    d <- as.integer(d)
    dInd <- which(datesEvalLast==d)+1 # +1 to skip the first entry (start with equal weights)
    SSent <- cov(SentData[(which(rownames(SentData) == d)-sentLookback):
                              which(rownames(SentData) == d) - 1, ]) # -1 to just look in past
    rdat <- ret[unique(pmax(which(rownames(ret)<=d) - 1,1)),] # from beginning to one day in past
    muStock <- colMeans(rdat)
    SStock <- cov(rdat)
    
    for(i in sentixDataNamesReg){
        for(k in 1:nrow(grid)){
            w <- as.numeric(grid[k,])
            weight <- paste(w, collapse = "-")
            eval(parse(text = paste0(i, "ObjValue[weight,] <- ", i, "ObjValue[weight,] + hWeighted(E[[weight]][[i]][dInd,])")))   
        }
    }
}
```

```{r}
n <- length(datesEvalLast)
for(i in sentixDataNamesReg){
    eval(parse(text = paste0(i, "ObjValue[,4] <- ", i, "ObjValue[,4]/n")))
}
sentixG1dispRegObjValue
```

not useful as higher weight for sentix results in higher objective value

```{r}
for(i in sentixDataNamesReg){
    eval(parse(text = paste0(i, "ObjValue[,4] <- ", i, "ObjValue[,4]/", i, "ObjValue[,3]")))
}
sentixG1dispRegObjValue
```
objective value stays roughly the same after dividing through weight

### highest return

```{r}
load(file.path(folderData, "Optimization", "EDispersionMin_gloggest2017-08-16---11-35"))
Eanalysis <- E
```


```{r}
sentixReturns <- matrix(NA, nrow = length(Eanalysis), ncol = ncol(Eanalysis[[1]]))
rownames(sentixReturns) <- names(Eanalysis)
colnames(sentixReturns) <- colnames(Eanalysis[[1]])
for(i in 1:length(Eanalysis)){
    sentixReturns[i,] <- Eanalysis[[i]][1,]
}
sentixReturns
colMeans(sentixReturns)
```
```{r}
m1 <- apply(sentixReturns, 2, function(x) max(x))
m2 <- apply(sentixReturns, 2, function(x) which.max(x))
m3 <- rownames(sentixReturns)[apply(sentixReturns, 2, function(x) which.max(x))]

data.frame("maximum return" = m1, "index of max return" = m2, "weights for function" = m3)
```

```{r}
strategy <- which.max(m1)
weight <- m2[strategy]
sentPfMaxReturn <- Eevolving[[weight]][[strategy]]
```


### highest Sharpe Ratio

```{r}
sentixSharpe <- matrix(NA, nrow = length(Eanalysis), ncol = ncol(Eanalysis[[1]]))
rownames(sentixSharpe) <- names(Eanalysis)
colnames(sentixSharpe) <- colnames(Eanalysis[[1]])
for(i in 1:length(Eanalysis)){
    sentixSharpe[i,] <- Eanalysis[[i]][3,]
}
# sentixSharpe
colMeans(sentixSharpe)
```

```{r}
m1 <- apply(sentixSharpe, 2, function(x) max(x))
m2 <- apply(sentixSharpe, 2, function(x) which.max(x))
m3 <- rownames(sentixSharpe)[apply(sentixSharpe, 2, function(x) which.max(x))]

data.frame("maximum return" = m1, "index of max return" = m2, "weights for function" = m3)
```
```{r}
strategy <- which.max(m1)
weight <- m2[strategy]
sentPfMaxSharpe <- Eevolving[[weight]][[strategy]]
```





## without sentiment (classic)

Calculate Portfolio evolvement (start with 100, how does it evolve)

```{r}
EclassicEvolving <- lapply(Eclassic, evolve)
```


TODO: look at implementation of VaR (Pfaff multiplied value by -100)

```{r}
analysePortfolio
```


```{r}
analysePortfolio(EclassicEvolving)
```

## Comparison

```{r}
# install.packages("SharpeR") # installs many other packages as well
# library(SharpeR)
```


```{r}
Rsent <- Return.calculate(sentPfMaxSharpe)
Rclas <- Return.calculate(EclassicEvolving[["GMV"]])

table.AnnualizedReturns(Rsent)
table.AnnualizedReturns(Rclas)

sr_test(x = Rsent, y = Rclas, paired = TRUE,alternative="greater")
```



# Portfolio Visualization

```{r}
# library(grDevices) # for color
```


```{r}
# pdf(file = paste0(getwd(), "/Plot/optimal 08-08/", "optimal Portfolios all", ".pdf"), width = 12, height = 8)
cols <- topo.colors(4)
plot(EclassicEvolving[[1]], lwd = 1, ylab = "Index", xlab = "", 
     col = cols[1], main = "Comparison of Allocation Strategies", 
     ylim = c(min(unlist(lapply(EclassicEvolving, min)), sentPfMaxReturn, sentPfMaxSharpe),
              max(unlist(lapply(EclassicEvolving, max)), sentPfMaxReturn, sentPfMaxSharpe)))
for(i in 2:length(EclassicEvolving)){
    eval(parse(text = paste0("lines(EclassicEvolving[[", i, "]], col = cols[", i, "])")))
}
legend("topleft", legend = c(names(EclassicEvolving), "sMaxR", "sMaxS"), col = c(cols, "red", "orange"), lty = 1, lwd = 2)
abline(h = 100, col = "gray")

lines(sentPfMaxReturn, col = "red", lwd = 2)
lines(sentPfMaxSharpe, col = "orange", lwd = 2)
# dev.off()
```