---
title: "old stuff"
author: "Stefan Glogger"
date: "18 August 2017"
output: pdf_document
---

# Data -> Sentix -> Dispersion

get results of calculation of dispersion


```{r}
load(file.path(folderData, "Sentix", "SentixCalculated"))
```

There might be a problem with duplicated dates!

```{r}
dates <- as.Date(sentix[[1]][,1], format = "%d.%m.%Y")
sum(duplicated(dates))
sum(dates==as.Date("2013-04-05"))
dates <- unique(dates)
```


```{r, cache=T}
sentixP1disp <- data.frame(DAX = unique(sentix[["DAX"]])$P_disp, 
                           row.names = as.Date(unique(sentix[["DAX"]])[,1], format = "%d.%m.%Y"))
sentixP1disp$TEC = unique(sentix[["TEC"]])$P_disp[unique(sentix[["TEC"]])$Datum %in% dates]
sentixP1disp$ESX50 = unique(sentix[["ESX50"]])$P_disp[unique(sentix[["ESX50"]])$Datum %in% dates]
sentixP1disp$SP5 = unique(sentix[["SP5"]])$P_disp[unique(sentix[["SP5"]])$Datum %in% dates]
sentixP1disp$NASDAQ = unique(sentix[["NASDAQ"]])$P_disp[unique(sentix[["NASDAQ"]])$Datum %in% dates]
sentixP1disp$NIKKEI = unique(sentix[["NIKKEI"]])$P_disp[unique(sentix[["NIKKEI"]])$Datum %in% dates]
sentixP1disp$BUND = unique(sentix[["BUND"]])$P_disp[unique(sentix[["BUND"]])$Datum %in% dates]
sentixP1disp$TBOND = unique(sentix[["TBOND"]])$P_disp[unique(sentix[["TBOND"]])$Datum %in% dates]

sentixI1disp <- data.frame(DAX = unique(sentix[["DAX"]])$I_disp, 
                           row.names = as.Date(unique(sentix[["DAX"]])[,1], format = "%d.%m.%Y"))
sentixI1disp$TEC = unique(sentix[["TEC"]])$I_disp[unique(sentix[["TEC"]])$Datum %in% dates]
sentixI1disp$ESX50 = unique(sentix[["ESX50"]])$I_disp[unique(sentix[["ESX50"]])$Datum %in% dates]
sentixI1disp$SP5 = unique(sentix[["SP5"]])$I_disp[unique(sentix[["SP5"]])$Datum %in% dates]
sentixI1disp$NASDAQ = unique(sentix[["NASDAQ"]])$I_disp[unique(sentix[["NASDAQ"]])$Datum %in% dates]
sentixI1disp$NIKKEI = unique(sentix[["NIKKEI"]])$I_disp[unique(sentix[["NIKKEI"]])$Datum %in% dates]
sentixI1disp$BUND = unique(sentix[["BUND"]])$I_disp[unique(sentix[["BUND"]])$Datum %in% dates]
sentixI1disp$TBOND = unique(sentix[["TBOND"]])$I_disp[unique(sentix[["TBOND"]])$Datum %in% dates]


sentixG1disp <- data.frame(DAX = unique(sentix[["DAX"]])$G_disp, 
                           row.names = as.Date(unique(sentix[["DAX"]])[,1], format = "%d.%m.%Y"))
sentixG1disp$TEC = unique(sentix[["TEC"]])$G_disp[unique(sentix[["TEC"]])$Datum %in% dates]
sentixG1disp$ESX50 = unique(sentix[["ESX50"]])$G_disp[unique(sentix[["ESX50"]])$Datum %in% dates]
sentixG1disp$SP5 = unique(sentix[["SP5"]])$G_disp[unique(sentix[["SP5"]])$Datum %in% dates]
sentixG1disp$NASDAQ = unique(sentix[["NASDAQ"]])$G_disp[unique(sentix[["NASDAQ"]])$Datum %in% dates]
sentixG1disp$NIKKEI = unique(sentix[["NIKKEI"]])$G_disp[unique(sentix[["NIKKEI"]])$Datum %in% dates]
sentixG1disp$BUND = unique(sentix[["BUND"]])$G_disp[unique(sentix[["BUND"]])$Datum %in% dates]
sentixG1disp$TBOND = unique(sentix[["TBOND"]])$G_disp[unique(sentix[["TBOND"]])$Datum %in% dates]



sentixP6disp <- data.frame(DAX = unique(sentix[["DAXm"]])$P_disp, 
                           row.names = as.Date(unique(sentix[["DAXm"]])[,1], format = "%d.%m.%Y"))
sentixP6disp$TEC = unique(sentix[["TECm"]])$P_disp[unique(sentix[["TECm"]])$Datum %in% dates]
sentixP6disp$ESX50 = unique(sentix[["ESX50m"]])$P_disp[unique(sentix[["ESX50m"]])$Datum %in% dates]
sentixP6disp$SP5 = unique(sentix[["SP5m"]])$P_disp[unique(sentix[["SP5m"]])$Datum %in% dates]
sentixP6disp$NASDAQ = unique(sentix[["NASDAQm"]])$P_disp[unique(sentix[["NASDAQm"]])$Datum %in% dates]
sentixP6disp$NIKKEI = unique(sentix[["NIKKEIm"]])$P_disp[unique(sentix[["NIKKEIm"]])$Datum %in% dates]
sentixP6disp$BUND = unique(sentix[["BUNDm"]])$P_disp[unique(sentix[["BUNDm"]])$Datum %in% dates]
sentixP6disp$TBOND = unique(sentix[["TBONDm"]])$P_disp[unique(sentix[["TBONDm"]])$Datum %in% dates]


sentixI6disp <- data.frame(DAX = unique(sentix[["DAXm"]])$I_disp, 
                           row.names = as.Date(unique(sentix[["DAXm"]])[,1], format = "%d.%m.%Y"))
sentixI6disp$TEC = unique(sentix[["TECm"]])$I_disp[unique(sentix[["TECm"]])$Datum %in% dates]
sentixI6disp$ESX50 = unique(sentix[["ESX50m"]])$I_disp[unique(sentix[["ESX50m"]])$Datum %in% dates]
sentixI6disp$SP5 = unique(sentix[["SP5m"]])$I_disp[unique(sentix[["SP5m"]])$Datum %in% dates]
sentixI6disp$NASDAQ = unique(sentix[["NASDAQm"]])$I_disp[unique(sentix[["NASDAQm"]])$Datum %in% dates]
sentixI6disp$NIKKEI = unique(sentix[["NIKKEIm"]])$I_disp[unique(sentix[["NIKKEIm"]])$Datum %in% dates]
sentixI6disp$BUND = unique(sentix[["BUNDm"]])$I_disp[unique(sentix[["BUNDm"]])$Datum %in% dates]
sentixI6disp$TBOND = unique(sentix[["TBONDm"]])$I_disp[unique(sentix[["TBONDm"]])$Datum %in% dates]


sentixG6disp <- data.frame(DAX = unique(sentix[["DAXm"]])$G_disp, 
                           row.names = as.Date(unique(sentix[["DAXm"]])[,1], format = "%d.%m.%Y"))
sentixG6disp$TEC = unique(sentix[["TECm"]])$G_disp[unique(sentix[["TECm"]])$Datum %in% dates]
sentixG6disp$ESX50 = unique(sentix[["ESX50m"]])$G_disp[unique(sentix[["ESX50m"]])$Datum %in% dates]
sentixG6disp$SP5 = unique(sentix[["SP5m"]])$G_disp[unique(sentix[["SP5m"]])$Datum %in% dates]
sentixG6disp$NASDAQ = unique(sentix[["NASDAQm"]])$G_disp[unique(sentix[["NASDAQm"]])$Datum %in% dates]
sentixG6disp$NIKKEI = unique(sentix[["NIKKEIm"]])$G_disp[unique(sentix[["NIKKEIm"]])$Datum %in% dates]
sentixG6disp$BUND = unique(sentix[["BUNDm"]])$G_disp[unique(sentix[["BUNDm"]])$Datum %in% dates]
sentixG6disp$TBOND = unique(sentix[["TBONDm"]])$G_disp[unique(sentix[["TBONDm"]])$Datum %in% dates]
```

# portfolio optimization - sentiment - varying weights

```{r, eval=FALSE}
# cores <- detectCores()
# 
# if(Sys.getenv("USERNAME") == "Stefan"){
#     cl <- makeCluster(cores - 1)
# } else if(Sys.getenv("USERNAME") == "gloggest"){
#     cl <- makeCluster(cores) # use server fully
# } else
#     stop("Who are you???")
# 
# 
# E <- list()
# tt <- numeric(nrow(grid)*length(sentixDataNamesReg)) # track time to evaluate code
# 
# # registerDoParallel(cl)
# registerDoSNOW(cl)
# E <- foreach(weightInd = 1:2, .export = sentixDataNames, .packages = c("fPortfolio", "FRAPO")) %do% {
#     w <- as.numeric(grid[weightInd,])
#     weightName <- paste(w, collapse = "-") # needed later to store result
#     
#     for(strategy in sentixDataNames){
#         SentData <- get(strategy)
#         rownames(SentData) <- as.integer(as.Date(rownames(SentData))) # for faster comparison below -> cast date to integer
#         erg <- matrix(NA, nrow = length(datesEvalLast)+1, ncol = numAsset) # +1 to lookup every weight
#         rownames(erg) <- c("1000-01-01", paste(datesEvalLast))
#         erg[1, ] <- rep(1/numAsset, numAsset)
#         
#         for(d in datesEvalLast){
#             dInd <- which(datesEvalLast==d)
#             
#             
#             dispersion <- SentData[which(rownames(SentData) == d)- 1, ] # -1 to just look at the sentiment in past
#             rdat <- ret[unique(pmax(which(rownames(ret)<=d) - 1,1)),] # from beginning to one day in past
#             muStock <- colMeans(rdat)
#             SStock <- cov(rdat)
#             
#             erg[dInd+1,] <- donlp2NLP(start = erg[dInd,], obj = hDispersionDirectMin, 
#                          par.lower = rep(0, numAsset), ineqA = IneqA, 
#                          ineqA.lower = 1.0, ineqA.upper = 1.0)$solution
#         }
#         
#         E[[weightName]][[strategy]] <- erg
#         tt[(weightInd-1)*nrow(grid) + which(sentixDataNamesReg == strategy)] <- proc.time()[3]
#     }
# }
# stopCluster(cl)
# 
# save(E, file = file.path(folderData, "Optimization", paste0("EDispersionMin_", Sys.getenv("USERNAME"), format(Sys.time(), "%Y-%m-%d---%H-%M"))))
```



\newpage
# Data Derivations ->  further consideration

For the moment, I (Stefan) don't think that the regressing is thoroughly based, so this (updating of code) is skipped for now.

## regress Sentiment

We first regress each sentiment on the other sentiments and just go with the non-explained intercept. From these, we calculate the covariance matrix.

```{r, eval=F, cache=T}
i <- sentixDataNames[1]
parse(text = paste0(i, "Reg", " <- ", "regSent(", i, ")"))
for (i in sentixDataNames){
    eval(parse(text = paste0(i, "Reg", " <- ", "regSent(", i, ")")))
}

sentixDataNamesReg <- c()
i = 1
parse(text = paste0("sentixDataNamesReg <- ", "c(sentixDataNamesReg, \"", sentixDataNames[i], "Reg\")"))
for(i in sentixDataNames){
    eval(parse(text = paste0("sentixDataNamesReg <- ", "c(sentixDataNamesReg, \"", i, "Reg\")")))
}

```

```{r, eval=F}
i <- sentixDataNames[i]
parse(text = paste0(i, "RegCov", " <- ", "cov(", i, "Reg)"))
for(i in sentixDataNames){
    eval(parse(text = paste0(i, "RegCov", " <- ", "cov(", i, "Reg)")))
}
```



## regression

### regress one on all others

We regress one sentiment variable on all other sentiment variables and take the residuals. 

```{r, eval=F}
regSentResidual
```


```{r, eval=F}
sentixI1dispResiduals50 <- regSentResidual(sentixI1disp, consider = 50, func = mean)
summary(sentixI1dispResiduals50)

sentixI1dispResiduals10 <- regSentResidual(sentixI1disp, consider = 10, func = mean)
summary(sentixI1dispResiduals10)
```

That is not useful! The values differ after the 16th position after decimal point.

Look at what causes this good explanation of one variable by its others:

```{r, eval=F}
dat <- sentixI1disp
for(k in colnames(dat)){
    # generate formula (regress one column on all the others while using 'consider' previous points)
    print(form <- as.simple.formula(setdiff(colnames(dat), k), k))
    print(summary(lm(form, data = dat[max((200-50),1):200,])))
}
```

### do (correct?) adoptation

get Covariance to 0 by regressing one on all before and so on (compare to Portfolio Analysis Theorem 3.5)

```{r, eval=F}

```


# Optimization -> mrc

```{r, eval=FALSE}
ergSentixNames <- c()
i = 1
parse(text = paste0("ergSentixNames <- ", "c(ergSentixNames, \"erg", sentixDataNames[i], "\")"))
for(i in sentixDataNames){
    eval(parse(text = paste0("ergSentixNames <- ", "c(ergSentixNames, \"erg", i, "\")")))
}
```




### mrc


start optimization with equal weights and then start each iteration with result of previous iteration


roughly 30 seconds per strategy and weight (on laptop stefan)
```{r, eval=FALSE}
nrow(grid)*length(sentixDataNamesReg)*30 # Sekunden
nrow(grid)*length(sentixDataNamesReg)*30/60 # Minuten
nrow(grid)*length(sentixDataNamesReg)*30/60/60 # Stunden
```

roughly 14 seconds per strategy and weight (on laptop stefan)
```{r, eval=FALSE}
nrow(grid)*length(sentixDataNamesReg)*14 # Sekunden
nrow(grid)*length(sentixDataNamesReg)*14/60 # Minuten
nrow(grid)*length(sentixDataNamesReg)*14/60/60 # Stunden
```


Generate a list holding all data with structure (levels of list)
weights of goal function -> strategy -> dates -> weights of assets

```{r, eval=FALSE}
# sentLookback <- 20
# 
# E <- list()
# tt <- numeric(nrow(grid)*length(sentixDataNamesReg)) # track time to evaluate code
# 
# for(weightInd in 1:nrow(grid)){
#     w <- as.numeric(grid[weightInd,])
#     weightName <- paste(w, collapse = "-") # needed later to store result
#     
#     for(strategy in sentixDataNamesReg){
#         SentData <- get(strategy)
#         rownames(SentData) <- as.integer(as.Date(rownames(SentData))) # for faster comparison below -> cast date to integer
#         erg <- matrix(NA, nrow = length(datesEvalLast)+1, ncol = numAsset) # +1 to lookup every weight
#         rownames(erg) <- c("1000-01-01", paste(datesEvalLast))
#         erg[1, ] <- rep(1/numAsset, numAsset)
#         
#         for(d in datesEvalLast){
#             dInd <- which(datesEvalLast==d)
#             
#             SSent <- cov(SentData[(which(rownames(SentData) == d)-sentLookback):
#                                       which(rownames(SentData) == d) - 1, ]) # -1 to just look in past
#             rdat <- ret[unique(pmax(which(rownames(ret)<=d) - 1,1)),] # from beginning to one day in past
#             muStock <- colMeans(rdat)
#             SStock <- cov(rdat)
#             
#             erg[dInd+1,] <- donlp2NLP(start = erg[dInd,], obj = hWeighted, 
#                          par.lower = rep(0, numAsset), ineqA = IneqA, 
#                          ineqA.lower = 1.0, ineqA.upper = 1.0)$solution
#         }
#         
#         E[[weightName]][[strategy]] <- erg
#         tt[(weightInd-1)*nrow(grid) + which(sentixDataNamesReg == strategy)] <- proc.time()[3]
#     }
# }
# save(E, file = file.path(folderData, "Optimization", paste0("Eserver_", format(Sys.time(), "%Y-%m-%d---%H-%M"))))
```

# 50 Optimization - with sentiment

## seems to not be used

, we name it *anDisp*. We furthermore assume that the annual dispersion equals the average dispersion.

```{r}
anDisp <- lapply(sDisp, function(x) {colMeans(x[,-1])})
```


# from "functions.R"

```{r}
source("parameters.R")

# Data Input --------------------------------------------------------------



# # data input of Sentex files
# dataSentex <- function(fileName){
#   temp <- read.csv2(fileName, stringsAsFactors = F)
#   for (i in 2:ncol(temp)){
#     temp[,i] <- as.numeric((temp[,i]))
#   }
#   temp[,1] <- as.Date(temp[,1], format = "%d.%m.%Y")
#   return(temp)
# }

# # update data
# ## take data, reduced dates, indexes where duplicated
# updateDataSentex <- function(dat, dateRed){
#   temp <- dat[dat$Datum %in% dateRed,]
#   temp <- unique(temp)
#   return(temp)
# }



# Plot --------------------------------------------------------------------



# # plot index with sentiment
# plotIndexSent <- function(dat){
#   ### in same graph
#   # https://stackoverflow.com/questions/6142944/how-can-i-plot-with-2-different-y-axes
#   
#   pdf(file = paste0(folderPlotIndexSent, "/", deparse(substitute(dat)), ".pdf"), 
#       width = 12, height = 8)
#   
#   # parameter for second y-axis (for sentiment)
#   ylim2 = c(0.3, 0.9)
#   # add extra space to right margin of plot within frame
#   par(mar=c(5, 4, 4, 5) + 0.1)
#   
#   plot(dat$Datum, dat$Index, type = "l", xlab = "Date", ylab = "Index",  lwd = 2)
#   par(new=T)
#   plot(dat$Datum, dat$Sent_Is, type = "l",  axes = F, 
#        xlab="", ylab="", col = "red", ylim = ylim2)
#   par(new=T)
#   plot(dat$Datum, dat$Sent_Ps, type = "l",  axes = F, 
#        xlab="", ylab="", col = "blue", ylim = ylim2)
#   
#   title(deparse(substitute(dat)))
#   legend("topleft",legend=c("Index","Is", "Ps"),
#          text.col=c("black","red", "blue"),lty=c(1,1,1),col=c("black","red", "blue"))
#   axis(side=4, at = pretty(ylim2))
#   mtext("Sentiment",side=4,line=3) 
#   
#   dev.off()
# }
# 
# 
# # Optimization ------------------------------------------------------------
# 
# 
# # ** Upgrade Sentex Data --------------------------------------------------
# 
# # library(FSelector) # to generate formula easily
# 
# ### developped further to regSent
# # dispersionSent <- function(dat){
# #   temp <- dat
# #   
# #   for(i in 1:nrow(dat)){
# #     for(k in colnames(dat)){
# #       # generate formula (regress one column on all the others while using all the previous data (including today))
# #       form <- as.simple.formula(setdiff(colnames(dat), k), k)
# #       temp[i, k] <- unname(lm(form, data = dat[1:i,])$coefficients[1])
# #     }
# #   }
# #   
# #   return(temp)
# # }
# 
# ### take data with sentiment data (dispersion or herfindahl) with rows (dates) and columns (indizes)
# regSent <- function(dat, consider = 50){
#     temp <- dat
#     
#     for(i in 1:nrow(dat)){
#         for(k in colnames(dat)){
#             # generate formula (regress one column on all the others while using 'consider' previous points)
#             form <- as.simple.formula(setdiff(colnames(dat), k), k)
#             temp[i, k] <- unname(lm(form, data = dat[max((i-consider),1):i,])$coefficients[1])
#         }
#     }
#     
#     return(temp)
# }

### input:  data with sentiment data (dispersion or herfindahl) with rows (dates) and columns (indizes)
###         days to consider
### output: list containing regression results
### problem:    resulting object is large (~ 200mb)
regSentAll <- function(dat, consider = 50){
    temp <- list()
    
    for(i in 1:nrow(dat)){
        temp[[i]] <- list()
        for(k in colnames(dat)){
            # generate formula (regress one column on all the others while using 'consider' previous points)
            form <- as.simple.formula(setdiff(colnames(dat), k), k)
            temp[[i]][[k]] <- unname(lm(form, data = dat[max((i-consider),1):i,]))
        }
    }
    
    return(temp)
}

### input:  data with sentiment data (dispersion or herfindahl) with rows (dates) and columns (indizes)
###         days to consider
###         func function to apply on residuals
### output: object of same structure as dat, containing the results of func applied on the residuals
regSentResidual <- function(dat, consider = 50, func = mean){
    temp <- dat
    
    for(i in 1:nrow(dat)){
        for(k in colnames(dat)){
            # generate formula (regress one column on all the others while using 'consider' previous points)
            form <- as.simple.formula(setdiff(colnames(dat), k), k)
            temp[i,k] <- func(unname(lm(form, data = dat[max((i-consider),1):i,])$residuals))
        }
    }
    
    return(temp)
}

### input:  data with sentiment data (dispersion or herfindahl) with rows (dates) and columns (indizes)
###         days to consider
###         func function to apply on residuals
### proced: regress on everything before
### output: object of same structure as dat, containing the results of func applied on the residuals
regSentResidualCorrect <- function(dat, consider = 50, func = mean){
    temp <- dat
    
    for(i in 1:nrow(dat)){
        for(k in colnames(dat)){
            # generate formula (regress one column on all the others while using 'consider' previous points)
            form <- as.simple.formula(setdiff(colnames(dat), k), k)
            temp[i,k] <- func(unname(lm(form, data = dat[max((i-consider),1):i,])$residuals))
        }
    }
    
    return(temp)
}

# ** Actual Optimization -----------------------------------------------------



g <- function(x){
  return(c(1.0001-sum(x), sum(x) - 0.9999))
}

# goal function with 3 criteria
### give mu and S to speed up (do not need to calculate it every time out of R)
### TODO: somehow not working -> have to give global parameters
f <- function(x, w, muStock, SStock, targetRpm, targetVolpa, SSent){
  y <- numeric(3)
  y[1] <- -1.0 * w[1] * drop(crossprod(x, muStock)) / targetRpm
  y[2] <- w[2] * drop(sqrt(t(x) %*% SStock %*% x)) * sqrt(12) / targetVolpa
  y[3] <- w[3] * sum((mrc(x, SSent))^2)
  return(y)
}

h <- function(x){
  y <- numeric(3)
  y[1] <- -1.0 * w[1] * drop(crossprod(x, muStock)) / targetRpm
  y[2] <- w[2] * drop(sqrt(t(x) %*% SStock %*% x)) * sqrt(12) / targetVolpa
  y[3] <- w[3] * sum((mrc(x, SSent))^2)
  return(y)
}

hWeighted <- function(x){
  return(sum(h(x)))
}


## take dispersion directly and sum ist up, which we want to minimize
## global parameters: w, muStock, targetRpm, SStock, targetVolpa, dispersion (sentiment values direct)
hDispersionDirectMin <- function(x){
    y <- numeric(3)
    y[1] <- -1.0 * w[1] * drop(crossprod(x, muStock)) / targetRpm
    y[2] <- w[2] * drop(sqrt(t(x) %*% SStock %*% x)) * sqrt(12) / targetVolpa
    y[3] <- w[3] * drop(crossprod(x, dispersion))
    return(sum(y))
}


# library(mco)
# library(FRAPO)
# minimize sentiment via marginal contribution to risk 
### TODO take closer look if this is really how Sentiment can be included (-> portfolio analysis)
# minSentiment <- function(muStock, SStock, targetRpm, targetVolpa, SSent, w = w, f = f, g = g){
#   NAsset = length(muStock)
#   ans <- nsga2(f, NAsset, 3,
#                w = w, muStock = muStock, SStock = SStock, 
#                targetRpm = targetRpm, targetVolpa = targetVolpa, SSent = SSent,
#                lower.bounds = rep(0, NAsset), upper.bounds = rep(1, NAsset), 
#                constraints = g, cdim = 2, 
#                popsize = 500)
#   return(ans)
# }

minSentiment <- function(SSent){
  NAsset = length(muStock)
  ans <- nsga2(h, NAsset, 3,
               lower.bounds = rep(0, NAsset), upper.bounds = rep(1, NAsset),
               constraints = g, cdim = 2,
               popsize = 500)
  return(ans)
}


# Analysis of Portfolio --------------------------------------------------

## Take weights in each date of datesEval and calculate the portfolio return
evolve <- function(x){
    retFac <- ret[rownames(ret)%in%datesEval[2:length(datesEval)],]*
        x[1:(length(datesEval)-1),] # weight at time t and on these returns to time t+1 made
    retFac <- 1+rowSums(retFac)
    retFac <- c(100, retFac) # initialize with 100 and multiply the returns (next line)
    return(timeSeries(cumprod(retFac), charvec = datesEval))
}

## Take list (each element is another portfolio) as input and return portfolio characteristics
## uses global variables: ret, datesEval
analysePortfolio <- function(l){
    RsClassic <- matrix(unlist(lapply(l, Return.calculate)), ncol = length(l)) # return from time to time
    RsTSClassic <- na.omit(xts(RsClassic, order.by = as.Date(datesEval)))
    bench <- xts(rep(0, nrow(RsTSClassic)), order.by = as.Date(datesEval)[-1]) # benchmark 0 everytime
    
    S1 <- as.matrix(table.AnnualizedReturns(RsTSClassic, Rf = bench)) # scale is chosen automatically to 'weekly'
    S2 <- -1*VaR(RsTSClassic) # 95% as default (outputs small negative value)
    
    ans <- rbind(S1, S2)
    colnames(ans) <- names(l)
    rownames(ans) <- c("Return (p.a.)", "StdDev. Risk (p.a.)", "Sharpe Ratio", "VaR 95% (p.a.)")
    return(round(ans, 3))
}

# Spielwiese --------------------------------------------------------------


# library(Rdonlp2) ## needed for donlp2NLP
optMinSent <- function(SSent){
  
}
```



# 70 Visualization 


## One Dispersion, different weights

We visualize the different portfolio returns of each time window of each dispersion in a histogram.

The results can (also) be found in "\\IR-Phase FIM-Statistik\\R-Research Project Statistics\\Plot Optimization\\Dispersion Const".

### on its own

not so interesting, nicer below

```{r}
for(d in datesNames){
    retOverTime <- apply(1+ret[get(d),], 2, prod)
    
    for(i in names(xDispConst[[d]])){
        retDispTime <- numeric(length(xDispConst[[d]][[i]]))
        names(retDispTime) <- names(xDispConst[[d]][[i]])
        for(j in 1:length(retDispTime)){
            retDispTime[j] <- crossprod(xDispConst[[d]][[i]][[j]]$x, retOverTime)
        }
        
        t <- paste(d, i, sep = " - ")
        pdf(file.path(getwd(), "Plot Optimization", "Dispersion Const", paste0(t, ".pdf")), width = 10, height = 4)
        plot(retDispTime, main = t)
        dev.off()
    }
}
```

### together (all different dispersions)

```{r}
for(d in datesNames){
    cols <- rainbow(length(xDispConst[[d]]))
    retOverTime <- apply(1+ret[get(d),], 2, prod)
    retDispTime <- data.frame(w = names(xDispConst[[d]][[1]]))
    
    for(i in names(xDispConst[[d]])){
        for(j in 1:nrow(retDispTime)){
            retDispTime[j,i] <- crossprod(xDispConst[[d]][[i]][[j]]$x, retOverTime)
        }
    }
    
    ylim = c(min(retDispTime[,-1]), max(retDispTime[,-1]))
    plot(retDispTime[,2], ylim = ylim, col = cols[1], main = d)
    for(i in 3:ncol(retDispTime)){
        par(new=T)
        plot(retDispTime[,i], ylim = ylim, axes = F, xlab = "", ylab = "", col = cols[i-1])
    }
    legend("bottomright", legend = names(xDispConst[[d]]), col = cols, lty = 1)
    
    pdf(file.path(getwd(), "Plot Optimization", "Dispersion Const", paste0("0", d, ".pdf")), width = 10, height = 8)
    plot(retDispTime[,2], ylim = ylim, col = cols[1], main = d)
    for(i in 3:ncol(retDispTime)){
        par(new=T)
        plot(retDispTime[,i], ylim = ylim, axes = F, xlab = "", ylab = "", col = cols[i-1])
    }
    legend("bottomright", legend = names(xDispConst[[d]]), col = cols, lty = 1)
    dev.off()
}

```



## Change of Portfolio weights

First, we want to depict the change of portfolio weights over time.

#### area plot

We want to generate an area plot of the varying weights.

```{r}
dat = xDispVarEval$datesEvalBear$P1$x

plotWeightsArea <- function(datName){
    dat <- datName$x
    alpha = 0.5 
    rn <- rownames(dat)
    dat <- t(apply(dat, 1, cumsum))
    dat <- as.data.frame(dat)
    dat$date <- as.Date(rownames(dat))
    
    ggplot(dat, aes(x=date)) +
        geom_area(aes(y=dat[,7], fill=colnames(dat)[7]), alpha=alpha) +
        geom_area(aes(y=dat[,6], fill=colnames(dat)[6]), alpha=alpha) +
        geom_area(aes(y=dat[,5], fill=colnames(dat)[5]), alpha=alpha) +
        geom_area(aes(y=dat[,4], fill=colnames(dat)[4]), alpha=alpha) +
        geom_area(aes(y=dat[,3], fill=colnames(dat)[3]), alpha=alpha) +
        geom_area(aes(y=dat[,2], fill=colnames(dat)[2]), alpha=alpha) +
        geom_area(aes(y=dat[,1], fill=colnames(dat)[1]), alpha=alpha) +
        scale_fill_discrete(name="Index") +
        labs(title = deparse(substitute(datName)),
             y = "Weight",
             x = "Date")
}

plotWeightsArea(xDispVarEval[["datesEvalBear"]][["P1"]])
```

#### Line Plot

As the area might be a bit complicated to understand (just the visible height of the area matters, not the absolute maximal y value), we use a line plot for visualization.

```{r}
plotWeightsLines
```

### TODO: change of weights with turnover

TODO: include turnover as bar plot with second y-axis to visualize how much a portfolio has to be changed.

```{r, eval=FALSE}
plotWeightsLines <- function(datName, d, s){
    dat <- datName[[d]][[s]]$x
    dat <- as.data.frame(dat)
    dat$date <- as.Date(rownames(dat))
    dat$turnover <- datName[[d]][[s]]$turnover
    
    colBackground <- colsEvalDates[d]
        
    plotCommand <- paste0("ggplot(dat, aes(x=date)) +")
    for(i in 1:(ncol(dat)-3)){
        plotCommand <- paste0(plotCommand, "geom_line(aes(y=dat[,",i,"], color = colnames(dat)[", i, "])) +")
    }
    plotCommand <- paste0(plotCommand, "geom_line(aes(y=dat[,",ncol(dat)-2,"], color = colnames(dat)[", ncol(dat)-2, "]))")
        
    eval(parse(text = plotCommand))+
        ylim(0, 1)+
        geom_bar(aes(y=dat$turnover, colour = "Turnover"), stat = "identity")+
        scale_y_continuous(sec.axis = sec_axis(~., name = "Turnover"))+
        labs(title = paste("Time:", d),
             subtitle = paste("Portfolio:", s),
             y = "Weight ",
             x = "Date") +
        scale_color_discrete(name = "Index") +
        theme(panel.background = element_rect(fill = alpha(colBackground, 0.2)))
}
```

```{r, eval=FALSE}
plotWeightsLinesComplete <- function(dat, fileName){
    lateximport <- c(paste0("\\subsection{",fileName,"}"))
    
    for(d in datesEvalNames){
        lateximport <- c(lateximport, paste0("\\subsubsection{", fileName, " - ", d, "}"))
        
        for(s in names(dat[[d]])){
            # plotWeightsLines(dat, d, s)
            
            title <- paste0(fileName, "-", d,"-", s, ".pdf")
            pdf(file.path(getwd(), "Plot", title), width = 10, height = 4)
            plot(plotWeightsLines(dat, d, s))
            dev.off()
            
            lateximport <- c(lateximport, paste0("\\includegraphics[width=\\textwidth]{",title,"}"))
        }
    }
    
    fileConnection <- file(file.path(getwd(), "Plot", paste0("0",fileName,".txt")))
    writeLines(lateximport, fileConnection)
    close(fileConnection)
}
```

to plot multiple plots on one plot <http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/>

```{r}
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

##### weights turnover underneath

use those package to generate equal width plots <https://stackoverflow.com/questions/16255579/how-can-i-make-consistent-width-plots-in-ggplot-with-legends>


```{r}
library(gtable)    
library(grid)
library(gridExtra) 

```


```{r}
plotWeightsLinesWithTurnover <- function(datName, d, s){
    dat <- datName[[d]][[s]]$x
    dat <- as.data.frame(dat)
    dat$date <- as.Date(rownames(dat))
    dat$turnover <- datName[[d]][[s]]$turnover
    
    colBackground <- colsEvalDates[d]
        
    plotCommand <- paste0("ggplot(dat, aes(x=date)) +")
    for(i in 1:(ncol(dat)-3)){
        plotCommand <- paste0(plotCommand, "geom_line(aes(y=dat[,",i,"], color = colnames(dat)[", i, "])) +")
    }
    plotCommand <- paste0(plotCommand, "geom_line(aes(y=dat[,",ncol(dat)-2,"], color = colnames(dat)[", ncol(dat)-2, "]))")
        
    p1 <- eval(parse(text = plotCommand))+
      ylim(0, 1)+
      labs(title = paste("Time:", d),
           subtitle = paste("Portfolio:", s),
           y = "Weight ",
           x = "Date",
           color = "Portfolios") +
      theme(panel.background = element_rect(fill = alpha(colBackground, 0.2)))
    p2 <- ggplot(dat, aes(x=date))+
      ylim(0,1)+
      geom_bar(aes(y=dat$turnover), stat = "identity", fill = "black")+
      labs(title = paste("Time:", d),
           subtitle = paste("Turnover:", s),
           y = "Turnover",
           x = "Date") +
      theme(panel.background = element_rect(fill = alpha(colBackground, 0.1)))
    
    # equal width
    gA <- ggplotGrob(p1)
    gB <- ggplotGrob(p2)
    
    # Set the widths
    gB$widths <- gA$widths
    
    # Arrange the two charts.
    # The legend boxes are centered
    grid.newpage()
    grid.arrange(gA, gB, nrow = 2)
    
}
```

```{r}
plotWeightsLinesWithTurnoverComplete <- function(dat, fileName){
    lateximport <- c(paste0("\\subsection{",fileName,"}"))
    
    for(d in datesEvalNames){
        lateximport <- c(lateximport, paste0("\\subsubsection{", fileName, " - ", d, "}"))
        
        for(s in names(dat[[d]])){
            # plotWeightsLines(dat, d, s)
            
            title <- paste0(fileName, "-", d,"-", s, ".pdf")
            pdf(file.path(getwd(), "Plot", title), width = 10, height = 8)
            plotWeightsLinesWithTurnover(dat, d, s)
            dev.off()
            
            lateximport <- c(lateximport, paste0("\\includegraphics[width=\\textwidth]{",title,"}"))
        }
    }
    
    fileConnection <- file(file.path(getwd(), "Plot", paste0("0",fileName,".txt")))
    writeLines(lateximport, fileConnection)
    close(fileConnection)
}
```